{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Assesment Notebook\n",
    "\n",
    "This notebook displays basic info and plots. \n",
    "It should run on your local computer, provided that you've \n",
    "download the \\*-exp.fits and \\*-exp.h5 files, but you can run\n",
    "at jupyter.nersc.gov, once you've setup your \n",
    "environment (see below).\n",
    "\n",
    "***WARNING:*** If you open a .h5 file (fit outputs) ***make sure you use the 'r' option***. Otherwise, you might overwrite the file and lose its contents. @TODO: add a protection againts this attack, for now ***please be careful.***\n",
    "\n",
    "***Reminder***: your modifications will modify your local copy of the notebook, if you want to share those modifications, please do a PR. You might lose them if the notebook is modified and you update picca to the latest master. If you are unsure what this means, make a copy of the file (e.g. to your home) and work with it.\n",
    "\n",
    "***How to setup the jupyter environment at NERSC***:\n",
    "(you need to do this only once)\n",
    "\n",
    "First, create a conda environment dedicated to picca plots:\n",
    "    \n",
    "    conda config --add channels intel conda-forge defaults\n",
    "    conda create -n picca_plots ipykernel fitsio h5py scipy matplotlib healpy\n",
    "    source activate picca_plots\n",
    "    cd $HOME/igmhub/picca\n",
    "    python setup.py install\n",
    "    python -m ipykernel install --user --name picca_plots --display-name picca_plots\n",
    "    source deactivate\n",
    "\n",
    "Point your browser to jupyter.nersc.gov. After you login, you should see a `picca_plots` kernel. Double click on it. Navigate the left menu to open $HOME/igmhub/picca/tutorials/QA_plots.ipynb \n",
    "\n",
    "***notes:***\n",
    "\n",
    " * The setup.py install step will install picca only in your picca_plots environment and will not conflict with your previous installation, independently of whether you used PYTHONPATH or setup.py install (we need the setup.py install setp in the env because PYTHONPATH is not visible from the jupyter.nersc.gov).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import fitsio\n",
    "import healpy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rcParams\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from picca import wedgize\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "rcParams['lines.linewidth'] = 4\n",
    "rcParams['axes.labelsize'] = 20\n",
    "rcParams['xtick.labelsize'] = 18\n",
    "rcParams['ytick.labelsize'] = 18\n",
    "rcParams['legend.fontsize'] = 20\n",
    "plt.rc('text',usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***INFO:*** you can safely ignore the h5py error message (if any) in the cell above\n",
    "\n",
    "Set up the different path to the data and to the mocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get mocks\n",
    "mock_base = '/project/projectdirs/desi/mocks/lya_forest/london/v4.0/'\n",
    "quick_ver = 'quick-0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get mock products\n",
    "mock = {}\n",
    "mock['raw_path'] = '/project/projectdirs/desi/mocks/lya_forest/picca/london/v4.0/quick-0.0/'\n",
    "mock['delta'] = mock['raw_path']+'/deltas/'\n",
    "mock['delta_attributes'] = mock['raw_path']+'/iter.fits.gz'\n",
    "mock['delta_log'] = mock['raw_path']+'/input.log'\n",
    "mock['cf1d'] = '/global/homes/h/hdumasde/Run_programs/igmhub/picca/CoLoRe_mocks/cf1d.fits.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get data products\n",
    "data = {}\n",
    "data['raw_path'] = '/global/homes/h/hdumasde/Run_programs/igmhub/picca/DR14_results/'\n",
    "data['delta'] = data['raw_path']+'/Delta_LYA/Delta/'\n",
    "data['delta_attributes'] = data['raw_path']+'/Delta_LYA/Log/delta_attributes.fits.gz'\n",
    "data['cf1d'] = data['raw_path']+'/Correlations/cf1d.fits.gz'\n",
    "data['cf'] = data['raw_path']+'/Correlations_redone/e_cf.fits.gz'\n",
    "data['xcf'] = data['raw_path']+'/Correlations_redone/e_xcf.fits.gz'\n",
    "data['fit_cf'] = data['raw_path']+'/Correlations_redone/Fit/LYA_LYA/result.h5'\n",
    "data['fit_xcf'] = data['raw_path']+'/Correlations_redone/Fit/LYA_QSO/result.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Catalogs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catalogs\n",
    "cat_path = {'master':mock_base+'master.fits',\n",
    "            'zcat':mock_base+quick_ver+'/zcat.fits',\n",
    "            'desiDRQ':mock_base+quick_ver+'/zcat_desi_drq.fits',\n",
    "            'random':mock_base+'/master_randoms.fits.gz'}\n",
    "redshift_key = {'master':'Z_QSO_RSD', 'zcat':'Z', 'desiDRQ':'Z','random':'Z'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redshift distribution of the different catalogs\n",
    "\n",
    "The following cell calculates the redshift distribution of the \n",
    "catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = sp.arange(1.5,5.,0.01)\n",
    "for name,path in cat_path.items():\n",
    "    h = fitsio.FITS(path)\n",
    "    z = h[1][redshift_key[name]][:]\n",
    "    h.close()\n",
    "    plt.hist(z,bins=bins,histtype='step',label=name,density=True,linewidth=4)\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$\\mathrm{\\#}$')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following function allows to have a 2d histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_2DTProfile(ar1, ar2, ar3, nbBinsX, nbBinsY,we=None):\n",
    "\n",
    "    if we is None:\n",
    "        we = sp.ones_like(ar1)\n",
    "    d = sp.array(list(zip(ar1,ar2,ar3)))\n",
    "    number, axis = sp.histogramdd( d, (nbBinsX,nbBinsY,1))\n",
    "    weight, axis = sp.histogramdd( d, (nbBinsX,nbBinsY,1), weights=we  )\n",
    "    mean,   axis = sp.histogramdd( d, (nbBinsX,nbBinsY,1), weights=we*ar3)\n",
    "    err,    axis = sp.histogramdd( d, (nbBinsX,nbBinsY,1), weights=we*(ar3**2.))\n",
    "\n",
    "    w = number>1\n",
    "    mean[w]   /= weight[w]\n",
    "    err[w]    = sp.sqrt((err[w]/weight[w]-mean[w]**2.)/number[w])\n",
    "\n",
    "    mean   = mean[:,:,0]\n",
    "    err    = err[:,:,0]\n",
    "    number = number[:,:,0]\n",
    "\n",
    "    return mean, err, number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density of objects on the sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.random.seed(42)\n",
    "nbQSO = 1000000\n",
    "for name,path in cat_path.items():\n",
    "    h = fitsio.FITS(path)\n",
    "    ra = h[1]['RA'][:]\n",
    "    dec = h[1]['DEC'][:]\n",
    "    z = h[1][redshift_key[name]][:]\n",
    "    h.close()\n",
    "    w = sp.random.choice(sp.arange(ra.size,dtype=int),size=min(ra.size,nbQSO),replace=False)\n",
    "    ra = ra[w]\n",
    "    dec = dec[w]\n",
    "    z = z[w]\n",
    "    extent = [ra.min(), ra.max(), dec.min(), dec.max()]\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14,7))\n",
    "    plt.suptitle(r'$\\mathrm{'+name+'}$',fontsize=20)\n",
    "    \n",
    "    mean_nb, err_nb, number_nb = Get_2DTProfile(ra, dec, sp.ones(ra.size), 200, 100)\n",
    "    number_nb = sp.transpose(number_nb)\n",
    "    number_nb[number_nb==0.] = sp.nan\n",
    "    plot1 = ax1.imshow(number_nb, interpolation='nearest', origin='lower',extent=extent, aspect='auto')\n",
    "    cbar1 = plt.colorbar(plot1, ax=ax1)\n",
    "    cbar1.set_label(r'$\\#$',size=20)\n",
    "    cbar1.update_ticks()\n",
    "    ax1.set_xlabel(r'$\\mathrm{R.A. \\, [deg]}$')\n",
    "    ax1.set_ylabel(r'$\\mathrm{Dec. \\, [deg]}$')\n",
    "    ax1.grid()\n",
    "    \n",
    "    mean_z, err_z, number_z = Get_2DTProfile(ra, dec, z, 200, 100)\n",
    "    mean_z = sp.transpose(mean_z)\n",
    "    number_z = sp.transpose(number_z)\n",
    "    mean_z[number_z==0.] = sp.nan\n",
    "    plot2 = ax2.imshow(mean_z, interpolation='nearest', origin='lower',extent=extent, aspect='auto')\n",
    "    cbar2 = plt.colorbar(plot2,ax=ax2)\n",
    "    cbar2.set_label(r'$<z>$',size=20)\n",
    "    cbar2.update_ticks()\n",
    "    ax2.set_xlabel(r'$\\mathrm{R.A. \\, [deg]}$')\n",
    "    ax2.set_ylabel(r'$\\mathrm{Dec. \\, [deg]}$')\n",
    "    ax2.grid()\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitude distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mag = {}\n",
    "name_mag[0] = 'g mag: decam'\n",
    "name_mag[1] = 'r mag: decam'\n",
    "name_mag[2] = 'z mag: decam'\n",
    "name_mag[3] = 'wise1'\n",
    "name_mag[4] = 'wise2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = fitsio.FITS(cat_path['zcat'])\n",
    "mag = h['ZCATALOG']['MAG'][:]\n",
    "z = h['ZCATALOG']['Z'][:]\n",
    "ra = h['ZCATALOG']['RA'][:]\n",
    "dec = h['ZCATALOG']['DEC'][:]\n",
    "h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = sp.arange(mag.min(), mag.max(), 0.1)\n",
    "for i in range(5):\n",
    "    plt.hist(mag[:,i],bins=bins,linewidth=4,histtype='step',label=r'$\\mathrm{'+name_mag[i]+'}$')\n",
    "plt.xlabel(r'magnitude')\n",
    "plt.ylabel(r'number')\n",
    "plt.legend(loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following function allows to get the profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_TProfile(ar1, ar2, nbBin1, we2=None):\n",
    "\n",
    "    if we2 is None:\n",
    "        we2 = sp.ones_like(ar1)\n",
    "    number, axisX, axisY = sp.histogram2d(ar1, ar2, (nbBin1,1))\n",
    "    weight, axisX, axisY = sp.histogram2d(ar1, ar2, (nbBin1,1), weights=we2)\n",
    "    mean,   axisX, axisY = sp.histogram2d(ar1, ar2, (nbBin1,1), weights=we2*ar2)\n",
    "    err,    axisX, axisY = sp.histogram2d(ar1, ar2, (nbBin1,1), weights=we2*(ar2**2.))\n",
    "\n",
    "    ### find the axis X\n",
    "    axisX = sp.array([ axisX[i]+(axisX[i+1]-axisX[i])/2. for i in range(0,axisX.size-1) ])\n",
    "    \n",
    "    ### Get only not empty bins\n",
    "    bool_number = (number[:,0]>1)\n",
    "    \n",
    "    axisX  = axisX[bool_number]\n",
    "    number = number[:,0][bool_number]\n",
    "    weight = weight[:,0][bool_number]\n",
    "    mean   = mean[:,0][bool_number]\n",
    "    err    = err[:,0][bool_number]\n",
    "\n",
    "    mean  = mean/weight\n",
    "    err   = sp.sqrt((err/weight-mean**2.)/number)\n",
    "\n",
    "    return axisX, mean, err, number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitude vs. redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = sp.arange(1.5, 5., 0.01)\n",
    "for i in range(5):\n",
    "    axisX, mean, err, number = Get_TProfile(z,mag[:,i], bins)\n",
    "    plt.plot(axisX, mean,linewidth=4,label=r'$\\mathrm{'+name_mag[i]+'}$')\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$mag$')\n",
    "plt.legend(loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitude on the sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):        \n",
    "    extent = [ra.min(), ra.max(), dec.min(), dec.max()]\n",
    "    mean, err, number = Get_2DTProfile(ra, dec, mag[:,i], 200, 100)\n",
    "    mean = sp.transpose(mean)\n",
    "    number = sp.transpose(number)\n",
    "    mean[number==0.] = sp.nan\n",
    "    plt.imshow(mean, interpolation='nearest', origin='lower',extent=extent, aspect='auto')\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(r'$<\\mathrm{'+name_mag[i]+'}>$',size=20)\n",
    "    cbar.update_ticks()\n",
    "    plt.xlabel(r'$\\mathrm{R.A.} \\, [\\mathrm{deg}]$')\n",
    "    plt.ylabel(r'$\\mathrm{Dec.} \\, [\\mathrm{deg}]$')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Lya Transmission__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get all transmission files\n",
    "fs = sp.sort(glob.glob(mock_base+'/*/*/transmission-*-*.fits'))\n",
    "fs = fs[:10]\n",
    "lLYA = 1215.67\n",
    "lminforest = 1215.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Along the observed wavelength \n",
    "lObs_min = 3000.\n",
    "lObs_max = 8000.\n",
    "lObs_stack = sp.arange(lObs_min,lObs_max,1.)\n",
    "z_stack = lObs_stack/lLYA-1.\n",
    "T_stack = sp.zeros(lObs_stack.size)\n",
    "TVar_stack = sp.zeros(lObs_stack.size)\n",
    "n_stack = sp.zeros(lObs_stack.size)\n",
    "T_stack_delta = sp.zeros(lObs_stack.size)\n",
    "TVar_stack_delta = sp.zeros(lObs_stack.size)\n",
    "n_stack_delta = sp.zeros(lObs_stack.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Along the rest-frame wavelength\n",
    "lRF_min = 100.\n",
    "lRF_max = 4000.\n",
    "lRF_stack = sp.arange(lRF_min,lRF_max,1.)\n",
    "T_lRF_stack = sp.zeros(lRF_stack.size)\n",
    "TVar_lRF_stack = sp.zeros(lRF_stack.size)\n",
    "n_lRF_stack = sp.zeros(lRF_stack.size)\n",
    "T_lRF_stack_delta = sp.zeros(lRF_stack.size)\n",
    "TVar_lRF_stack_delta = sp.zeros(lRF_stack.size)\n",
    "n_lRF_stack_delta = sp.zeros(lRF_stack.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the transmission\n",
    "for f in fs:\n",
    "    h = fitsio.FITS(f)\n",
    "    z = h['METADATA']['Z'][:]\n",
    "    lObs = h['WAVELENGTH'].read()\n",
    "    trans = h['TRANSMISSION'].read()\n",
    "    lRF = lObs/(1.+z[:,None])\n",
    "    lObs = lObs*sp.ones(z.size)[:,None]\n",
    "    w = lRF<lminforest\n",
    "    lObs = lObs[w]\n",
    "    lRF = lRF[w]\n",
    "    trans = trans[w]\n",
    "\n",
    "    bins = ( ( lObs-lObs_min )/(lObs_max-lObs_min)*lObs_stack.size ).astype(int)\n",
    "    T_stack += sp.bincount(bins,weights=trans,minlength=lObs_stack.size)\n",
    "    TVar_stack += sp.bincount(bins,weights=trans**2,minlength=lObs_stack.size)\n",
    "    n_stack += sp.bincount(bins,minlength=lObs_stack.size)\n",
    "\n",
    "    bins = ( ( lRF-lRF_min )/(lRF_max-lRF_min)*lRF_stack.size ).astype(int)\n",
    "    T_lRF_stack += sp.bincount(bins,weights=trans,minlength=lRF_stack.size)\n",
    "    TVar_lRF_stack += sp.bincount(bins,weights=trans**2,minlength=lRF_stack.size)\n",
    "    n_lRF_stack += sp.bincount(bins,minlength=lRF_stack.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalize the vectors (obseved wavelength)\n",
    "w = n_stack>0.\n",
    "T_stack[w] /= n_stack[w]\n",
    "TVar_stack[w] /= n_stack[w]\n",
    "TVar_stack -= T_stack**2\n",
    "trans_vs_lObs = interp1d(lObs_stack[w],T_stack[w],fill_value='extrapolate',kind='nearest')\n",
    "\n",
    "### Normalize the vectors (rest-frame wavelength)\n",
    "w = n_lRF_stack>0.\n",
    "T_lRF_stack[w] /= n_lRF_stack[w]\n",
    "TVar_lRF_stack[w] /= n_lRF_stack[w]\n",
    "TVar_lRF_stack -= T_lRF_stack**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the delta\n",
    "for f in fs:\n",
    "    h = fitsio.FITS(f)\n",
    "    z = h['METADATA']['Z'][:]\n",
    "    lObs = h['WAVELENGTH'].read()\n",
    "    trans = h['TRANSMISSION'].read()\n",
    "    h.close()\n",
    "    lRF = lObs/(1.+z[:,None])\n",
    "    lObs = lObs*sp.ones(z.size)[:,None]\n",
    "    w = lRF<lminforest\n",
    "    lObs = lObs[w]\n",
    "    lRF = lRF[w]\n",
    "    trans = trans[w]/trans_vs_lObs(lObs)-1.\n",
    "\n",
    "    bins = ( ( lObs-lObs_min )/(lObs_max-lObs_min)*lObs_stack.size ).astype(int)\n",
    "    T_stack_delta += sp.bincount(bins,weights=trans,minlength=lObs_stack.size)\n",
    "    TVar_stack_delta += sp.bincount(bins,weights=trans**2,minlength=lObs_stack.size)\n",
    "    n_stack_delta += sp.bincount(bins,minlength=lObs_stack.size)\n",
    "\n",
    "    bins = ( ( lRF-lRF_min )/(lRF_max-lRF_min)*lRF_stack.size ).astype(int)\n",
    "    T_lRF_stack_delta += sp.bincount(bins,weights=trans,minlength=lRF_stack.size)\n",
    "    TVar_lRF_stack_delta += sp.bincount(bins,weights=trans**2,minlength=lRF_stack.size)\n",
    "    n_lRF_stack_delta += sp.bincount(bins,minlength=lRF_stack.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalize the vectors (obseved wavelength)\n",
    "w = n_stack_delta>0.\n",
    "T_stack_delta[w] /= n_stack_delta[w]\n",
    "TVar_stack_delta[w] /= n_stack_delta[w]\n",
    "TVar_stack_delta -= T_stack_delta**2\n",
    "\n",
    "### Normalize the vectors (rest-frame wavelength)\n",
    "w = n_lRF_stack_delta>0.\n",
    "T_lRF_stack_delta[w] /= n_lRF_stack_delta[w]\n",
    "TVar_lRF_stack_delta[w] /= n_lRF_stack_delta[w]\n",
    "TVar_lRF_stack_delta -= T_lRF_stack_delta**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from measurement on data\n",
    "### The input mean flux that we were trying to match corresponds\n",
    "### to F(z=2.25)=0.8, and a slope in optical depth of (1+z)^3.2.\n",
    "A = -sp.log(0.8)/(1.+2.25)**3.2\n",
    "B = 3.2\n",
    "print(' optical depth = ', A, B)\n",
    "T_measure = sp.exp(-A*(1.+z_stack)**B)\n",
    "DVar_measure = 0.0018*(1.+z_stack)**(2.*2.9-2.)\n",
    "TVar_measure = DVar_measure*T_measure**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmission vs. redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = n_stack>0.\n",
    "plt.plot(z_stack[w],T_stack[w],linewidth=2,label=r'$\\mathrm{Mocks: \\, T}$')\n",
    "plt.plot(z_stack[w],T_measure[w],linewidth=2,label=r'$T = e^{-0.0051(1+z)^{3.2}}$')\n",
    "w = n_stack_delta>0.\n",
    "plt.plot(z_stack[w],T_stack_delta[w],linewidth=2,label=r'$\\mathrm{Mocks: \\, \\delta}$')\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$T(z)$')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "_=plt.ylim(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance of the transmission vs. of redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = n_stack>0.\n",
    "plt.plot(z_stack[w],TVar_stack[w],linewidth=2,label=r'$\\mathrm{Mocks:\\,T}$')\n",
    "plt.plot(z_stack[w],TVar_measure[w],linewidth=2,label=r'$Var(T) = 0.0018 (1+z)^{2*2.9-2} * <T(z)>^{2}$')\n",
    "w = n_stack_delta>0.\n",
    "plt.plot(z_stack[w],TVar_stack_delta[w],linewidth=2,label=r'$\\mathrm{Mocks:\\,\\delta}$')\n",
    "plt.plot(z_stack[w],DVar_measure[w],linewidth=2,label=r'$Var(\\delta) = 0.0018 (1+z)^{2*2.9-2}$')\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$Var(T)(z)$')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "_=plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmission vs. rest-frame wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = n_lRF_stack>0.\n",
    "plt.plot(lRF_stack[w],T_lRF_stack[w],linewidth=2,label=r'$\\mathrm{Mocks:\\,T}$')\n",
    "w = n_lRF_stack_delta>0.\n",
    "plt.plot(lRF_stack[w],T_lRF_stack_delta[w],linewidth=2,label=r'$\\mathrm{Mocks:\\,\\delta}$')\n",
    "plt.xlabel(r'$\\lambda_{\\mathrm{R.F.}}$')\n",
    "plt.ylabel(r'$T$')\n",
    "plt.legend()\n",
    "plt.ylim(-0.2,1)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance of the transmission vs. rest-frame wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = n_lRF_stack>0.\n",
    "plt.plot(lRF_stack[w],TVar_lRF_stack[w],linewidth=2,label=r'$\\mathrm{Mocks:\\,T}$')\n",
    "w = n_lRF_stack_delta>0.\n",
    "plt.plot(lRF_stack[w],TVar_lRF_stack_delta[w],linewidth=2,label=r'$\\mathrm{Mocks:\\,\\delta}$')\n",
    "plt.xlabel(r'$\\lambda_{\\mathrm{R.F.}}$')\n",
    "plt.ylabel(r'$Var(T)$')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Example spectrum__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the different path to spectrum\n",
    "trans_path = mock_base+'/0/0/transmission-16-0.fits'\n",
    "spec_path = mock_base+quick_ver+'/spectra-16/0/0/spectra-16-0.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get delta nside\n",
    "h = fitsio.FITS(mock['delta_attributes'])\n",
    "nside = h[1].read_header()['NSIDE']\n",
    "h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the spectrum\n",
    "h = fitsio.FITS(spec_path)\n",
    "hra = h['FIBERMAP']['RA_TARGET'][:]\n",
    "hde = h['FIBERMAP']['DEC_TARGET'][:]\n",
    "tid = h['FIBERMAP']['TARGETID'][:]\n",
    "b_ll = sp.log10(h['B_WAVELENGTH'].read())\n",
    "b_iv = h['B_IVAR'].read()*(h['B_MASK'].read()==0)\n",
    "b_fl = h['B_FLUX'].read()\n",
    "r_ll = sp.log10(h['R_WAVELENGTH'].read())\n",
    "r_iv = h['R_IVAR'].read()*(h['R_MASK'].read()==0)\n",
    "r_fl = h['R_FLUX'].read()\n",
    "z_ll = sp.log10(h['Z_WAVELENGTH'].read())\n",
    "z_iv = h['Z_IVAR'].read()*(h['Z_MASK'].read()==0)\n",
    "z_fl = h['Z_FLUX'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Transmission\n",
    "h = fitsio.FITS(trans_path)\n",
    "z = h['METADATA']['Z'][:]\n",
    "ra = h['METADATA']['RA'][:]\n",
    "de = h['METADATA']['DEC'][:]\n",
    "lObs = h['WAVELENGTH'].read()\n",
    "trans = h['TRANSMISSION'].read()\n",
    "h.close()\n",
    "lRF = lObs/(1.+z[:,None])\n",
    "lObs = lObs*sp.ones(z.size)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the first n spectra\n",
    "for idx in range(1):\n",
    "    ra_idx = hra[idx]\n",
    "    de_idx = hde[idx]\n",
    "    z_idx = z[ra==hra[idx]][0]\n",
    "    tid_idx = tid[idx]\n",
    "\n",
    "    delt_pix = healpy.ang2pix(nside, sp.pi/2.-de_idx*sp.pi/180., ra_idx*sp.pi/180.)\n",
    "    delta = fitsio.FITS(mock['delta']+'/delta-'+str(delt_pix)+'.fits.gz')\n",
    "    deltaa = delta[str(tid_idx)]\n",
    "\n",
    "    nidx = sp.arange(ra.size)[ra==ra_idx][0]\n",
    "    plt.plot(10**b_ll,b_fl[idx,:],color='blue',label=r'$\\mathrm{Spectrum B}$',linewidth=1)\n",
    "    plt.plot(10**r_ll,r_fl[idx,:],color='red',label=r'$\\mathrm{Spectrum R}$',linewidth=1)\n",
    "    plt.plot(10**z_ll,z_fl[idx,:],color='orange',label=r'$\\mathrm{Spectrum Z}$',linewidth=1)\n",
    "    plt.plot(lObs[nidx,:],trans[nidx,:],color='black',label=r'$\\mathrm{Transmission}$',linewidth=1)\n",
    "    plt.plot(10**deltaa['LOGLAM'][:],deltaa['DELTA'][:],color='green',label=r'$\\mathrm{Delta}$',linewidth=1)\n",
    "    plt.plot(10**deltaa['LOGLAM'][:],deltaa['CONT'][:],color='violet',label=r'$\\mathrm{Continuum}$',linewidth=1)\n",
    "    \n",
    "    plt.title(r'$z_{q} = '+str(z[ra==hra[idx]][0])+'$')\n",
    "    plt.xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$')\n",
    "    plt.ylabel(r'$Flux$')\n",
    "    plt.legend(ncol=2,fontsize=10)\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __The delta field__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### List of all the delta attributes functions to plot\n",
    "all_delta_attributes = {'Mock':mock['delta_attributes'], 'Data':data['delta_attributes']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux stack vs. observed wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,path in all_delta_attributes.items():\n",
    "    h = fitsio.FITS(path)\n",
    "    loglam = h[1]['LOGLAM'][:]\n",
    "    stack  = h[1]['STACK'][:]\n",
    "    w = h[1]['WEIGHT'][:]>0.\n",
    "    loglam = loglam[w]\n",
    "    stack  = stack[w]\n",
    "    plt.plot(10.**loglam, stack, linewidth=4,marker='o',label=name)\n",
    "    h.close()\n",
    "plt.xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$')\n",
    "plt.ylabel(r'$\\mathrm{\\overline{Flux}}$')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean continuum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,path in all_delta_attributes.items():\n",
    "    h = fitsio.FITS(path)\n",
    "    loglam_rest = h[3]['LOGLAM_REST'][:]\n",
    "    mean_cont = h[3]['MEAN_CONT'][:]\n",
    "    w = h[3]['WEIGHT'][:]>0.\n",
    "    loglam_rest = loglam_rest[w]\n",
    "    mean_cont = mean_cont[w]\n",
    "    plt.plot(10.**loglam_rest, mean_cont, linewidth=4,marker='o',label=name)\n",
    "    h.close()\n",
    "plt.xlabel(r'$\\lambda_{\\mathrm{R.F.}} \\, [\\AA]$')\n",
    "plt.ylabel(r'$\\mathrm{\\overline{Flux}}$')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction to the pipeline variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,path in all_delta_attributes.items():\n",
    "    h = fitsio.FITS(path)\n",
    "    loglam = h[2]['LOGLAM'][:]\n",
    "    eta = h[2]['ETA'][:]\n",
    "    w = h[2]['NB_PIXELS'][:]>0.\n",
    "    loglam = loglam[w]\n",
    "    eta = eta[w]\n",
    "    plt.errorbar(10.**loglam, eta, linewidth=4,label=name)\n",
    "    h.close()\n",
    "plt.xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$')\n",
    "plt.ylabel(r'$\\eta$')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Scale Structure variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,path in all_delta_attributes.items():\n",
    "    h = fitsio.FITS(path)\n",
    "    loglam = h[2]['LOGLAM'][:]\n",
    "    var_lss = h[2]['VAR_LSS'][:]\n",
    "    w = h[2]['NB_PIXELS'][:]>0.\n",
    "    loglam = loglam[w]\n",
    "    var_lss = var_lss[w]\n",
    "    plt.errorbar(10.**loglam, var_lss, linewidth=4,label=name)\n",
    "    h.close()\n",
    "plt.xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$')\n",
    "plt.ylabel(r'$\\sigma^{2}_{\\mathrm{LSS}}$')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the contribution of the variation of the continuum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,path in all_delta_attributes.items():\n",
    "    h = fitsio.FITS(path)\n",
    "    loglam = h[2]['LOGLAM'][:]\n",
    "    fudge = h[2]['FUDGE'][:]\n",
    "    w = h[2]['NB_PIXELS'][:]>0\n",
    "    loglam = loglam[w]\n",
    "    fudge = fudge[w]\n",
    "    plt.errorbar(10.**loglam, fudge, linewidth=4,label=name)\n",
    "    h.close()\n",
    "plt.xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$')\n",
    "plt.ylabel(r'$\\mathrm{Fudge}$')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### List of all the correlation to plot\n",
    "all_cf1d = {'Mock':mock['cf1d'], 'Data':data['cf1d']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The variance of delta in the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The variance\n",
    "for name,path in all_cf1d.items():\n",
    "    try:\n",
    "        h = fitsio.FITS(path)\n",
    "    except:\n",
    "        print('Couldnt find file {}, skipping'.format(path))\n",
    "        continue\n",
    "    head = h[1].read_header() #- in the future replace '1' by '1DCOR'\n",
    "    llmin = head['LLMIN']\n",
    "    llmax = head['LLMAX']\n",
    "    dll = head['DLL']\n",
    "    n1d = int((llmax-llmin)/dll+1)\n",
    "    x = sp.arange(0.,n1d)*dll+llmin\n",
    "    y = h[1]['v1d'][:]\n",
    "    w = h[1]['wv1d'][:]>0.\n",
    "    x = x[w]\n",
    "    y = y[w]\n",
    "    plt.plot(10.**x,y,linewidth=4,label=name)\n",
    "    h.close()\n",
    "plt.xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA] $')\n",
    "plt.ylabel(r'$\\xi^{ff,1D}$')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The normalized correlation in the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The normalized correlation\n",
    "f, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(14,14))\n",
    "\n",
    "### all\n",
    "for name,path in all_cf1d.items():\n",
    "    try:\n",
    "        h = fitsio.FITS(path)\n",
    "    except:\n",
    "        print('cant find {}, skipping'.format(path))\n",
    "        continue\n",
    "    y = h[1]['c1d'][:] #- in the future replace '1' by '1DCOR'\n",
    "    binsize = dll\n",
    "    bins = sp.arange(y.size)\n",
    "    x = sp.power(10,bins*binsize)\n",
    "    w = h[1]['nc1d'][:]>0.\n",
    "    x = x[w]\n",
    "    y = y[w]\n",
    "    ax1.errorbar(x,y,marker='o',linewidth=4,label=name)\n",
    "    h.close()\n",
    "ax1.set_xlabel(r'$\\lambda_{1}/\\lambda_{2}$')\n",
    "ax1.set_ylabel(r'$\\xi^{ff,1D}_{normed}(1,2)$')\n",
    "ax1.legend()\n",
    "ax1.grid()\n",
    "\n",
    "### zoom\n",
    "ymin = 1.e6\n",
    "ymax = -1.e6\n",
    "for name,path in all_cf1d.items():\n",
    "    try:\n",
    "        h = fitsio.FITS(path)\n",
    "    except:\n",
    "        print(\"Can't find file {}, skipping\".format(path))\n",
    "        continue\n",
    "    y = h[1]['c1d'][:] #- in the future replace '1' by '1DCOR'\n",
    "    binsize = dll\n",
    "    bins = sp.arange(y.size)\n",
    "    x = sp.power(10,bins*binsize)\n",
    "    w = h[1]['nc1d'][:]>0.\n",
    "    x = x[w]\n",
    "    y = y[w]\n",
    "    ymin = min(ymin,y.min())\n",
    "    ymax = max(ymax,y[y!=1.].max())\n",
    "    ax2.errorbar(x,y,marker='o',linewidth=4,label=name)\n",
    "    h.close()\n",
    "ax2.set_xlim([0.999,1.05])\n",
    "ax2.set_ylim([ymin-0.05,ymax+0.05])\n",
    "ax2.set_xlabel(r'$\\lambda_{1}/\\lambda_{2}$')\n",
    "ax2.set_ylabel(r'$\\xi^{ff,1D}_{normed}(1,2)$')\n",
    "ax2.legend()\n",
    "ax2.grid()\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Fit results__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will print out a table with the fit parameters for the auto results.\n",
    "If you want the cross results instead change the first line to\n",
    "\n",
    "    fi = sorted(glob.glob(\"xcf*.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = sorted(glob.glob(mock['raw_path']+'/cf_z_2.2_2.4-exp.h5'))\n",
    "#fi = [mock['raw_path']+'/cf_z_{}_{}-exp.h5'.format(round(zmin,3),round(zmin+0.2,3)) for zmin in sp.arange(2.2,3,0.2)]\n",
    "ff = h5py.File(fi[0],'r')\n",
    "cosmo_pars = [\"bias_LYA\",\"beta_LYA\",\"bias_QSO\",\"beta_QSO\",\"ap\",\"at\"]\n",
    "all_pars = [p.decode('utf-8') for p in ff['best fit'].attrs['list of free pars']]\n",
    "bname0 = fi[0].replace(\".h5\",\"\")\n",
    "ff.close()\n",
    "\n",
    "print(\"{:20}\".format(\"\"),end=\"\")\n",
    "for f in fi:\n",
    "    print(\"{:^20}\".format(os.path.basename(f).replace(\"-exp.h5\",\"\")),end=\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"{:20}\".format(\"zeff\"),end=\"\")\n",
    "for f in fi:\n",
    "    ff = h5py.File(f,'r')\n",
    "    try:\n",
    "        zeff = ff['best fit'].attrs['zeff']\n",
    "    except:\n",
    "        print(\"PROBLEM: {}\".format(f))\n",
    "        continue\n",
    "    out = \"{}\".format(round(zeff,2))\n",
    "    print(\"{:^20}\".format(out),end=\"\")\n",
    "    ff.close()\n",
    "print(\"\")\n",
    "\n",
    "for par in cosmo_pars:\n",
    "    print(\"{:20}\".format(par),end=\"\")\n",
    "    for f in fi:\n",
    "        ff = h5py.File(f,'r')\n",
    "        if par in ff['best fit'].attrs:\n",
    "            p,dp = ff['best fit'].attrs[par]\n",
    "            out = \"{} +/- {}\".format(round(p,3), round(dp,3))\n",
    "            print(\"{:^20}\".format(out),end=\"\")\n",
    "        ff.close()\n",
    "    print(\"\")\n",
    "    \n",
    "for par in all_pars:\n",
    "    if par in cosmo_pars:\n",
    "        continue\n",
    "    print(\"{:20}\".format(par[:20]),end=\"\")\n",
    "    for f in fi:\n",
    "        ff = h5py.File(f,'r')\n",
    "        bname = f.replace(\".h5\",\"\")\n",
    "        pa = par.replace(bname0,bname)\n",
    "        if pa in ff['best fit'].attrs:\n",
    "            p,dp = ff['best fit'].attrs[pa]\n",
    "            out = \"{} +/- {}\".format(round(p,3), round(dp,3))\n",
    "            print(\"{:^20}\".format(out),end=\"\")\n",
    "        ff.close()\n",
    "    print(\"\")\n",
    "print(\"{:20}\".format(\"chi2/(ndata-npar)\"),end=\"\")\n",
    "for f in fi:\n",
    "    ff = h5py.File(f,'r')\n",
    "    chi2 = ff['best fit'].attrs['fval']\n",
    "    ndata = ff['best fit'].attrs['ndata']\n",
    "    npar = ff['best fit'].attrs['npar']\n",
    "    out = \"{}/({}-{})\".format(round(chi2,1),ndata,npar)\n",
    "    print(\"{:^20}\".format(out),end=\"\")\n",
    "    ff.close()\n",
    "print(\"\")\n",
    "print(\"{:20}\".format(\"probability\"),end=\"\")\n",
    "for f in fi:\n",
    "    ff = h5py.File(f,'r')\n",
    "    chi2 = ff['best fit'].attrs['fval']\n",
    "    ndata = ff['best fit'].attrs['ndata']\n",
    "    npar = ff['best fit'].attrs['npar']\n",
    "    proba = 1.-sp.stats.chi2.cdf(chi2,ndata-npar)\n",
    "    out = \"{}\".format(round(proba,2))\n",
    "    print(\"{:^20}\".format(out),end=\"\")\n",
    "    ff.close()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wedge plots\n",
    "\n",
    "The cells below display wedge plots for a given file.\n",
    "\n",
    "Change the value of `base` to the file you wish to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'cf_xcf_z_0_10-exp'\n",
    "toPlot = {}\n",
    "toPlot['Mock'] = { 'CORR':mock['raw_path']+'/'+base+'.fits', \n",
    "                  'FIT':mock['raw_path']+'/'+base+'.h5', \n",
    "                  'NAME':base }\n",
    "#toPlot['Mock'] = { 'CORR':mock['raw_path']+'/'+base+'.fits', \n",
    "#                  'FIT':mock['raw_path']+'/cf_xcf_z_0_10-exp.h5', \n",
    "#                  'NAME':base }\n",
    "#toPlot['Data'] = { 'CORR':data['cf'], \n",
    "#                  'FIT':data['fit_cf'], \n",
    "#                  'NAME': 'LYA(LYA)xLYA(LYA)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus=[0., 0.5, 0.8, 0.95, 1.]\n",
    "for mumin,mumax in zip(mus[:-1],mus[1:]):\n",
    "    for name,paths in toPlot.items():\n",
    "        h = fitsio.FITS(paths['CORR'])\n",
    "        ff = h5py.File(paths['FIT'],'r')\n",
    "        fit = ff[paths['NAME']+'/fit'][...]\n",
    "        ff.close()\n",
    "        da = h[1]['DA'][:]\n",
    "        co = h[1]['CO'][:]\n",
    "        rpmin = h[1].read_header()['RPMIN']\n",
    "        np = h[1].read_header()['NP']\n",
    "        h.close()\n",
    "        ff.close()\n",
    "        b = wedgize.wedge(mumin=mumin,mumax=mumax,rpmin=rpmin,nrp=np,absoluteMu=True)\n",
    "        r,d,c = b.wedge(da,co)\n",
    "        r,f,_ = b.wedge(fit,co)\n",
    "        plt.errorbar(r,d*r**2,yerr=sp.sqrt(c.diagonal())*r**2,fmt=\"o\",label=r'$\\mathrm{'+name+'}$')\n",
    "        plt.plot(r,f*r**2)\n",
    "    plt.ylabel(r\"$r^2\\xi(r)$\")\n",
    "    plt.xlabel(r\"$r~[\\mathrm{Mpc/h}]$\")\n",
    "    plt.title(r\"${}<\\mu<{}$\".format(mumin,mumax),fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## draw contours if they are there\n",
    "from picca.constants import cosmo\n",
    "zeff = 2.4\n",
    "#h_dr9 = 0.7\n",
    "Om_fid = 0.3147\n",
    "#cosmo_dr9 = cosmo(0.27)\n",
    "#DH_dr9 = c/h_dr9/cosmo_dr9.hubble(zeff)\n",
    "#DM_dr9 = cosmo_dr9.r_comoving(zeff)/h_dr9\n",
    "#rs_dr9 = 149.66 ## Mpc\n",
    "\n",
    "h = 0.6731\n",
    "cosmo = cosmo(Om_fid)\n",
    "rs_fid = 147.33 ## Mpc\n",
    "c = 300000 ## speed of light in km/s\n",
    "DH_fid = c/h/cosmo.hubble(zeff)\n",
    "DM_fid = cosmo.r_comoving(zeff)/h\n",
    "ff = h5py.File(toPlot['Mock']['FIT'],'r')\n",
    "chi2_min = ff['best fit'].attrs['fval']\n",
    "ap_best = ff['best fit'].attrs['ap']\n",
    "at_best = ff['best fit'].attrs['at']\n",
    "DH_best = ap_best*DH_fid\n",
    "DM_best = at_best*DM_fid\n",
    "ap_min = ff['chi2 scan/ap'].attrs['min']\n",
    "ap_max = ff['chi2 scan/ap'].attrs['max']\n",
    "nap = ff['chi2 scan/ap'].attrs['nb_bin']\n",
    "ap = sp.linspace(ap_min,ap_max,nap)\n",
    "DH = ap*DH_fid\n",
    "at_min = ff['chi2 scan/at'].attrs['min']\n",
    "at_max = ff['chi2 scan/at'].attrs['max']\n",
    "nat = ff['chi2 scan/ap'].attrs['nb_bin']\n",
    "at = sp.linspace(at_min,at_max,nat)\n",
    "DM = at*DM_fid\n",
    "index = ff['chi2 scan/result'].attrs['fval']\n",
    "plt.contour(DM/rs_fid,DH/rs_fid,ff['chi2 scan/result/values'][...][:,index].reshape(nat,-1)-chi2_min,\n",
    "           levels=[2.3,6,11.8],colors=['b','b','b'])\n",
    "plt.errorbar([DM_best[0]/rs_fid],[DH_best[0]/rs_fid],\n",
    "             xerr=[DM_best[1]/rs_fid],yerr=[DH_best[1]/rs_fid],fmt=\"o\")\n",
    "plt.plot([DM_fid/rs_fid],[DH_fid/rs_fid],\"o\",ms=10)\n",
    "#plt.plot([DM_dr9/rs_dr9],[DH_dr9/rs_dr9],\"o\",ms=10)\n",
    "plt.xlabel(r'$D_M/r_s$',fontsize=40)\n",
    "plt.ylabel(r'$D_H/r_s$',fontsize=40)\n",
    "plt.grid()\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuals\n",
    "\n",
    "The following cells plot the residuals = (data-fit)/sigma in 2D and their histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = fitsio.FITS(mock['raw_path']+\"/\"+base+\".fits\")\n",
    "rpmin = h[1].read_header()[\"RPMIN\"]\n",
    "rtmin = 0\n",
    "rpmax = h[1].read_header()[\"RPMAX\"]\n",
    "rtmax = h[1].read_header()[\"RTMAX\"]\n",
    "nrp = h[1].read_header()[\"NP\"]\n",
    "nrt = h[1].read_header()[\"NT\"]\n",
    "da = h[1]['DA'][:]\n",
    "rp = h[1]['RP'][:]\n",
    "rt = h[1]['RT'][:]\n",
    "r = sp.sqrt(rp**2+rt**2)\n",
    "dda = sp.sqrt(h[1]['CO'][:].diagonal())\n",
    "ff = h5py.File(toPlot['Mock']['FIT'],'r')\n",
    "fit = ff[base+\"/fit\"][...]\n",
    "plt.imshow(((da-fit)/dda).reshape(nrt,nrp),\n",
    "           extent=[rtmin,rtmax,rpmin,rpmax],\n",
    "           origin='lower',interpolation='nearest',aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "_=plt.hist((da-fit)/dda,bins=100)\n",
    "print('std: {}'.format(sp.std((da-fit)/dda)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hubble's diagram\n",
    "c = 300000. ## speed of light in km/s\n",
    "rs_fid = 147.33 ## sound horizon in Mpc/h (Planck's)\n",
    "\n",
    "z = sp.arange(0,4,0.1)\n",
    "plt.plot(z,cosmo.hubble(z)/(1+z),\"--\")\n",
    "plt.ylabel(r\"$\\dot{a}\\frac{r_s}{r^{fid}_s}\\mathrm{[kms^{-1}Mpc^{-1}]}$\",fontsize=20)\n",
    "plt.xlabel(\"redshift\")\n",
    "fi = [\"cf_z_2.2_2.4-exp\",\"cf_z_2.4_2.6-exp\",\"cf_z_2.6_2.8-exp\",\n",
    "      \"cf_z_2.8_3.0-exp\",\"cf_z_3.0_3.2-exp\",\"cf_z_3.2_5.0-exp\"]\n",
    "fi += [\"xcf_z_0_2.2-exp\",\"xcf_z_2.2_2.4-exp\",'xcf_z_2.6_2.8-exp']\n",
    "fi = [mock['raw_path']+\"/\"+f+\".fits\" for f in fi]\n",
    "\n",
    "for f in fi:\n",
    "    h = fitsio.FITS(f)\n",
    "    rp = h[1]['RP'][:]\n",
    "    rt = h[1]['RT'][:]\n",
    "    z  = h[1]['Z'][:]\n",
    "    r = sp.sqrt(rp**2+rt**2)\n",
    "    w = (r>80) & (r<120)\n",
    "    zeff = z[w].mean()\n",
    "    try:\n",
    "        ff = h5py.File(f.replace('.fits','.h5'),'r')\n",
    "    except:\n",
    "        continue\n",
    "    ap,dap = ff['best fit'].attrs['ap']\n",
    "    H = cosmo.hubble(zeff)/(1+zeff)/ap\n",
    "    dH = H*dap/ap\n",
    "    style=\"ro\"\n",
    "    if 'xcf' in f:\n",
    "        style=\"m^\"\n",
    "    plt.errorbar([zeff],[H],yerr=[dH],fmt=style)\n",
    "plt.title(\"Jim's plot\",fontsize=16)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slices plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'cf_z_2.65_3.05-exp'\n",
    "toPlot = {}\n",
    "toPlot['Mock'] = { 'CORR':mock['raw_path']+'/'+base+'.fits', 'FIT':mock['raw_path']+'/'+base+'.h5', 'NAME':base }\n",
    "#toPlot['Data'] = { 'CORR':data['cf'], 'FIT':data['fit_cf'], 'NAME': 'LYA(LYA)xLYA(LYA)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = sp.arange(10)\n",
    "for s in slices:\n",
    "    for name,paths in toPlot.items():\n",
    "        h = fitsio.FITS(paths['CORR'])\n",
    "        ff = h5py.File(paths['FIT'],'r')\n",
    "        fit = ff[paths['NAME']+'/fit'][...]\n",
    "        rp = h[1]['RP'][:]\n",
    "        rt = h[1]['RT'][:]\n",
    "        drt = h[1].read_header()['RTMAX'] / h[1].read_header()['NT']\n",
    "        da = h[1]['DA'][:]\n",
    "        er = sp.sqrt(sp.diag(h[1]['CO'][:]))\n",
    "        h.close()\n",
    "        ff.close()\n",
    "        w = (rp>=s*drt) & (rp<(s+1)*drt)\n",
    "        rp = rp[w]\n",
    "        rt = rt[w]\n",
    "        da = da[w]\n",
    "        fit = fit[w]\n",
    "        er = er[w]\n",
    "        plt.errorbar(rt,da,yerr=er,fmt=\"o\",label=r'$\\mathrm{'+name+'}$')\n",
    "        plt.plot(rt,fit)\n",
    "        ff.close()\n",
    "    plt.ylabel(r\"$\\xi(r)$\")\n",
    "    plt.xlabel(r\"$r_{\\parallel}~[\\mathrm{Mpc/h}]$\")\n",
    "    plt.title(r\"${}<r_\\perp<{}$\".format(int(s*drt),int((s+1)*drt)),fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlim(0,25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The covariance matrices\n",
    "\n",
    "Let's compare the covariance matrices of the data and of the mocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The auto-correlation\n",
    "toPlot = {}\n",
    "toPlot['Mock'] = { 'CORR':mock['raw_path']+'/xcf_z_0_2.35-exp.fits'}\n",
    "#toPlot['Data'] = { 'CORR':data['cf']}\n",
    "for name,paths in toPlot.items():\n",
    "    h = fitsio.FITS(paths['CORR'])\n",
    "    nb = h[1]['NB'][:]\n",
    "    co = sp.diag(h[1]['CO'][:])\n",
    "    plt.plot(nb*co,label=r'$\\mathrm{'+name+'}$')\n",
    "plt.xlabel(r\"$\\mathrm{bin\\,index}$\")\n",
    "plt.ylabel(r\"$C_{AA} N_{b}$\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The cross-correlation\n",
    "toPlot = {}\n",
    "toPlot['Mock'] = { 'CORR':mock['raw_path']+'/xcf_z_2.65_3.05-exp.fits'}\n",
    "#toPlot['Data'] = { 'CORR':data['xcf']}\n",
    "for name,paths in toPlot.items():\n",
    "    h = fitsio.FITS(paths['CORR'])\n",
    "    nb = h[1]['NB'][:]\n",
    "    co = sp.diag(h[1]['CO'][:])\n",
    "    plt.plot(nb*co,label=r'$\\mathrm{'+name+'}$')\n",
    "plt.xlabel(r\"$\\mathrm{bin\\,index}$\")\n",
    "plt.ylabel(r\"$C_{AA} N_{b}$\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The correlation matrix\n",
    "\n",
    "Let's look at the difference between the data and the mocks on the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The auto-correlation\n",
    "toPlot = {}\n",
    "toPlot['Mock'] = { 'CORR':mock['raw_path']+'/cf_z_2.65_3.05-exp.fits'}\n",
    "#toPlot['Data'] = { 'CORR':data['cf']}\n",
    "\n",
    "### Load\n",
    "corr = {}\n",
    "for name,paths in toPlot.items():\n",
    "    corr[name] = {}\n",
    "    h = fitsio.FITS(paths['CORR'])\n",
    "    corr[name]['CO'] = h[1]['CO'][:]\n",
    "    tvar = sp.diag(corr[name]['CO'])\n",
    "    corr[name]['NBBIN'] = tvar.size\n",
    "    corr[name]['NT'] = h[1].read_header()['NT']\n",
    "    corr[name]['BINSIZE'] = h[1].read_header()['RTMAX']/h[1].read_header()['NT']\n",
    "    tcor = corr[name]['CO']/sp.sqrt(tvar*tvar[:,None])\n",
    "    corr[name]['COR'] = tcor.copy()\n",
    "    h.close()\n",
    "\n",
    "### Plot\n",
    "ymin = 1.\n",
    "ymax = -1.\n",
    "for j in range(2):\n",
    "    for name,tc in corr.items():\n",
    "        c = tc['COR'].copy()\n",
    "        a = sp.array( [ sp.mean(sp.diagonal(c, offset=(tc['NT']*i+j))) for i in range(tc['NBBIN']//tc['NT']) ])\n",
    "        label = '\\mathrm{'+name+': \\, \\Delta r_{\\perp} = '+str(int(tc['BINSIZE']*j))+'\\,h^{-1}\\, \\mathrm{Mpc}}'\n",
    "        plt.plot(tc['BINSIZE']*sp.arange(tc['NBBIN']//tc['NT']),a,linewidth=4,marker='o',markersize=8, label=r'$'+label+'$')\n",
    "        ymin = min(ymin,a.min())\n",
    "        ymax = max(ymax,a[a!=1.].max())\n",
    "plt.xlabel(r'$\\Delta r_{\\parallel} \\, [h^{-1}\\, \\mathrm{Mpc}]$')\n",
    "plt.ylabel(r'$Corr_{AB}$')\n",
    "plt.xlim([-1.,100.])\n",
    "plt.ylim([ymin-0.01,ymax+0.01])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The cross-correlation\n",
    "toPlot = {}\n",
    "toPlot['Mock'] = { 'CORR':mock['raw_path']+'/xcf_z_2.65_3.05-exp.fits'}\n",
    "#toPlot['Data'] = { 'CORR':data['xcf']}\n",
    "\n",
    "### Load\n",
    "corr = {}\n",
    "for name,paths in toPlot.items():\n",
    "    corr[name] = {}\n",
    "    h = fitsio.FITS(paths['CORR'])\n",
    "    corr[name]['CO'] = h[1]['CO'][:]\n",
    "    tvar = sp.diag(corr[name]['CO'])\n",
    "    corr[name]['NBBIN'] = tvar.size\n",
    "    corr[name]['NT'] = h[1].read_header()['NT']\n",
    "    corr[name]['BINSIZE'] = h[1].read_header()['RTMAX']/h[1].read_header()['NT']\n",
    "    tcor = corr[name]['CO']/sp.sqrt(tvar*tvar[:,None])\n",
    "    corr[name]['COR'] = tcor.copy()\n",
    "    h.close()\n",
    "\n",
    "### Plot\n",
    "ymin = 1.\n",
    "ymax = -1.\n",
    "for j in range(2):\n",
    "    for name,tc in corr.items():\n",
    "        c = tc['COR'].copy()\n",
    "        a = sp.array( [ sp.mean(sp.diagonal(c, offset=(tc['NT']*i+j))) for i in range(tc['NBBIN']//tc['NT']) ])\n",
    "        label = '\\mathrm{'+name+': \\, \\Delta r_{\\perp} = '+str(int(tc['BINSIZE']*j))+'\\,h^{-1}\\, \\mathrm{Mpc}}'\n",
    "        plt.plot(tc['BINSIZE']*sp.arange(tc['NBBIN']//tc['NT']),a,linewidth=4,marker='o',markersize=8, label=r'$'+label+'$')\n",
    "        ymin = min(ymin,a.min())\n",
    "        ymax = max(ymax,a[a!=1.].max())\n",
    "plt.xlabel(r'$\\Delta r_{\\parallel} \\, [h^{-1}\\, \\mathrm{Mpc}]$')\n",
    "plt.ylabel(r'$Corr_{AB}$')\n",
    "plt.xlim([-1.,100.])\n",
    "plt.ylim([ymin-0.01,ymax+0.01])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "picca_plots",
   "language": "python",
   "name": "picca_plots"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
